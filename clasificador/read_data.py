import glob
import os
import cv2

import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mtplt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import requests
from scipy.stats import skew, norm, probplot, boxcox, f_oneway
from scipy import interp
from factor_analyzer import FactorAnalyzer
import math

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler
from keras.utils import to_categorical
from sklearn.model_selection import KFold
from keras import models
from keras import layers
from keras import regularizers
import keras as keras


def plot_model(epochs, accuracy_train, accuracy_val, loss_train, loss_val):
    fig2 = plt.figure(figsize=(20,30))
    fig2.subplots_adjust(wspace=0.2)

    values = range(1,epochs+1)
    ax = fig2.add_subplot(3,3,1)
    ax.plot(values, accuracy_train, 'g', label='Training accuracy')
    ax.plot(values, accuracy_val, 'b', label='validation accuracy')
    ax.set_title('Training and Validation accuracy')
    ax.set_xlabel('Epochs')
    ax.set_ylabel('Accuracy')
    ax.legend()

    ax = fig2.add_subplot(3,3,2)
    ax.plot(values, loss_train, 'g', label='Training Loss')
    ax.plot(values, loss_val, 'b', label='validation Loss')
    ax.set_title('Training and Validation Loss')
    ax.set_xlabel('Epochs')
    ax.set_ylabel('Loss')
    ax.legend()
    plt.show()


print('Reading files ...')
labels = ['Adposhel','BrowseFox','Hlux','Other','VBKrypt','Agent','Dinwod','Injector','Regrun','Vilsel','Allaple','Elex','InstallCore','Sality','Amonetize','Expiro','MultiPlug','Snarasite','Androm','Fasong','Neoreklami','Stantinko','Autorun','HackKMS','Neshta','VBA']
basicPath = "DATA/malevis_train_test_224x224/"

size_train = []
for target in labels: 
    path = basicPath + "train/" + target + "/*.*"
    size_train.append(len(glob.glob(path)))
     
size_test = []
for target in labels: 
    path = basicPath + "test/" + target + "/*.*"
    size_test.append(len(glob.glob(path)))

n_train, n_test = sum(size_train), sum(size_test)

# Creating the data
dim1,dim2,dim3 = 224,224,3
basicPath = "DATA/malevis_train_test_224x224/"

X_train_orig = np.zeros((n_train, dim1,dim2,dim3))
Y_train_orig = np.zeros((n_train, 1))

for i in range(len(labels)):
    target = labels[i]
    path = basicPath + "train/" + target + "/*.png"
    files = glob.glob(path)
    n =  0 if (i == 0) else (n + size_train[i-1])
    for j in range(len(files)):
        file = files[j]
        image = np.array(cv2.imread(file))
        image = image.astype('float32')/255
        X_train_orig[n+j, :, :, :] = image
        Y_train_orig[n+j] = i


X_train = X_train_orig.reshape(X_train_orig.shape[0], -1)
Y_train = to_categorical(Y_train_orig)

print('Creating the model ...')

model = models.Sequential()
model.add(layers.Dense(100, input_shape=(224*224*3,), activation='relu'))
model.add(layers.Dense(len(labels),activation='sigmoid'))
model.compile(optimizer = 'rmsprop',
                loss='categorical_crossentropy',
               metrics=['accuracy'])
               

print('Training the model ...')
model.fit(X_train, Y_train, epochs=3, batch_size = 500, verbose = 1)

#
#print("Creating Model ...")
#
#acc_per_fold = []
#loss_per_fold = []
#
#num_folds = 2
#
#epochs = 5
#batch_size = 120
#learning_rate = 0.0001
#regularizer_rate = 0.0008
#
#accuracy_train = np.array([])
#accuracy_val = np.array([])
#loss_train = np.array([])
#loss_val = np.array([])
#
#kf = KFold(n_splits= num_folds, random_state=None, shuffle=True)
#for train_index, validate_index in kf.split(X_train):
#    # Se separan los indices para training y validation dado el 5-fold cv
#    train_index, validate_index = list(train_index), list(validate_index)
#
#    # Se crea el modelo
#    network = models.Sequential()
#    network.add(layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)))
#    network.add(layers.MaxPooling2D(2,2))
#    network.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)))
#    network.add(layers.MaxPooling2D(2,2))
#    network.add(layers.Conv2D(64, (3,3), activation='relu', input_shape=(224, 224, 3)))
#    network.add(layers.MaxPooling2D(2,2))
#    network.add(layers.Flatten())
#    network.add(layers.Dense(1024,kernel_regularizer=regularizers.l2(regularizer_rate), activation='sigmoid'))
#    network.add(layers.Dense(len(labels),kernel_regularizer=regularizers.l2(regularizer_rate),activation='sigmoid'))
#
#    # train the model
#    optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate,)
#    network.compile(optimizer = optimizer,
#                loss='categorical_crossentropy',
#                metrics=['accuracy'])
#
#
#    # Entrenamos
#    history = network.fit(X_train[train_index,:], Y_train[train_index], validation_data=(X_train[validate_index,:],Y_train[validate_index]), epochs=epochs, batch_size = batch_size, shuffle = True,verbose=1)
#
#    try:
#        accuracy_train += np.array(history.history['accuracy'])
#        accuracy_val += np.array(history.history['val_accuracy'])
#        loss_train += np.array(history.history['loss'])
#        loss_val += np.array(history.history['val_loss'])
#
#    except:
#        accuracy_train = np.array(history.history['accuracy'])
#        accuracy_val = np.array(history.history['val_accuracy'])
#        loss_train = np.array(history.history['loss'])
#        loss_val = np.array(history.history['val_loss'])
#
#    # Evaluamos con validación
#    val_loss, val_acc = network.evaluate(X_train[validate_index,:],Y_train[validate_index])
#
#    acc_per_fold.append(val_acc * 100)
#    loss_per_fold.append(val_loss)
#
#
## Saco el promedio
#accuracy_train = accuracy_train/num_folds
#accuracy_val = accuracy_val/num_folds
#loss_train = loss_train/num_folds
#loss_val = loss_val/num_folds
#
#
#acc_avg = np.mean(acc_per_fold)
#loss_avg = np.mean(loss_per_fold)
#
#print('El accuracy promedio en 5-fold cross validation fue de {}'.format(acc_avg))
#print('La función de costo promedio en 5-fold cross validation fue de {}'.format(loss_avg))
#
#plot_model(epochs, accuracy_train,accuracy_val,loss_train,loss_val)
#
#
## Writing the data in binary compressed files
##print('Writing files ...')
##
##np.savez_compressed('X_train.npz', X_train)
##np.savez_compressed('Y_train.npz', Y_train)
##np.savez_compressed('X_test.npz', X_test)
##np.savez_compressed('Y_test.npz', Y_test)
